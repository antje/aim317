{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.0-1\")\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.2xlarge', \n",
    "                                          volume_size=50, \n",
    "                                          output_path=output_path)\n",
    "\n",
    "train_input = TrainingInput(train_data, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(validation_data, content_type=\"text/csv\")\n",
    "\n",
    "estimator.fit({'train': train_input, 'validation': validation_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Built-in algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 's3://sagemaker-us-west-2-170213232067/models/autopilot/automl-dm-01-15-28-40/transformed-data/dpp0/rpb/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = 's3://sagemaker-us-west-2-170213232067/models/autopilot/automl-dm-01-15-28-40/transformed-data/dpp0/rpb/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALGORITHM_OBJECTIVE_METRICS = {\n",
    "#     'xgboost': 'validation:accuracy',\n",
    "# }\n",
    "\n",
    "# STATIC_HYPERPARAMETERS = {\n",
    "#     'xgboost': {\n",
    "#         'objective': 'multi:softprob',\n",
    "#         'save_model_on_termination': 'true',\n",
    "#         'num_class': 5,\n",
    "#     },\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.parameter import CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "\n",
    "# ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES = {\n",
    "#     'xgboost': {\n",
    "#         'num_round': IntegerParameter(2, 1024, scaling_type='Logarithmic'),\n",
    "#         'max_depth': IntegerParameter(2, 8, scaling_type='Logarithmic'),\n",
    "#         'eta': ContinuousParameter(1e-3, 1.0, scaling_type='Logarithmic'),\n",
    "#         'gamma': ContinuousParameter(1e-6, 64.0, scaling_type='Logarithmic'),\n",
    "#         'min_child_weight': ContinuousParameter(1e-6, 32.0, scaling_type='Logarithmic'),\n",
    "#         'subsample': ContinuousParameter(0.5, 1.0, scaling_type='Linear'),\n",
    "#         'colsample_bytree': ContinuousParameter(0.3, 1.0, scaling_type='Linear'),\n",
    "#         'lambda': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "#         'alpha': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "#     },\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize best hyperparameters\n",
    "hyperparameters = {\n",
    "        'alpha': '0.6341904648402323',\n",
    "        'colsample_bytree': '0.7643693234655944',\n",
    "        'eta': '0.7580930059794856',\n",
    "        'gamma': '8.206415138503572e-06',\n",
    "        'lambda': '0.006616951593958346',\n",
    "        'max_depth': '4',\n",
    "        'min_child_weight': '0.0023579601131722906',\n",
    "        'num_round': '331',\n",
    "        'subsample': '0.8268991002618953',\n",
    "        'objective': 'multi:softprob',\n",
    "        'save_model_on_termination': 'true',\n",
    "        'num_class': '5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an output path where the trained model will be saved\n",
    "prefix = 'DEMO-xgboost-as-a-built-in-algo'\n",
    "output_path = 's3://{}/{}/{}/output'.format(bucket, prefix, 'reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.0-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.2xlarge', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data type and paths to the training and validation datasets\n",
    "content_type = \"libsvm\"\n",
    "train_input = TrainingInput(train_data, content_type=content_type)\n",
    "validation_input = TrainingInput(validation_data, content_type=content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 16:55:15 Starting - Starting the training job...\n",
      "2020-11-01 16:55:20 Starting - Launching requested ML instances......\n",
      "2020-11-01 16:56:31 Starting - Preparing the instances for training......\n",
      "2020-11-01 16:57:22 Downloading - Downloading input data...\n",
      "2020-11-01 16:58:06 Training - Training image download completed. Training in progress.\n",
      "2020-11-01 16:58:06 Uploading - Uploading generated training model\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value multi:softprob to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mERROR:root:\n",
      " does not follow LIBSVM label format <label>(:<weight>).\u001b[0m\n",
      "\u001b[34mERROR:sagemaker-containers:Reporting training FAILURE\u001b[0m\n",
      "\u001b[34mERROR:sagemaker-containers:framework error: \u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n",
      "    entrypoint()\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/training.py\", line 94, in main\n",
      "    train(framework.training_env())\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/training.py\", line 90, in train\n",
      "    run_algorithm_mode()\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/training.py\", line 68, in run_algorithm_mode\n",
      "    checkpoint_config=checkpoint_config\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 127, in sagemaker_train\n",
      "    train_dmatrix, val_dmatrix = get_validated_dmatrices(train_path, val_path, file_type, csv_weights, is_pipe)\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 78, in get_validated_dmatrices\n",
      "    validate_data_file_path(train_path, content_type)\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/data_utils.py\", line 260, in validate_data_file_path\n",
      "    _validate_libsvm_format(data_file_path)\n",
      "  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/data_utils.py\", line 224, in _validate_libsvm_format\n",
      "    line_snippet=line_to_validate[:50], file_name=file_path.split('/')[-1]))\u001b[0m\n",
      "\u001b[34msagemaker_algorithm_toolkit.exceptions.UserError: First line '\u001b[0m\n",
      "\u001b[34m...' of file 'chunk_48.csv.out' is not 'LIBSVM' format. Please ensure the file is in 'LIBSVM' format.\n",
      "\u001b[0m\n",
      "\u001b[34mFirst line '\u001b[0m\n",
      "\u001b[34m...' of file 'chunk_48.csv.out' is not 'LIBSVM' format. Please ensure the file is in 'LIBSVM' format.\u001b[0m\n",
      "\n",
      "2020-11-01 16:58:53 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sagemaker-xgboost-2020-11-01-16-55-14-022: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n    entrypoint()\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/training.py\", line 94, in main\n    train(framework.training_env())\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/training.py\", line 90, in train\n    run_algorithm_mode()\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/training.py\", line 68, in run_algorithm_mode\n    checkpoint_config=checkpoint_config\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 127, in sagemaker_train\n    train_dmatrix, val_dmatrix = get_validated_dmatrices(train_path, val_path, file_type, csv_weights, is_pipe)\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 78, in get_validated_dmatrices\n    validate_data_f",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4862b109cb7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Execute the XGBoost training job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalidation_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3273\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3275\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2863\u001b[0m                 ),\n\u001b[1;32m   2864\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2865\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2866\u001b[0m             )\n\u001b[1;32m   2867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sagemaker-xgboost-2020-11-01-16-55-14-022: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n    entrypoint()\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/training.py\", line 94, in main\n    train(framework.training_env())\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/training.py\", line 90, in train\n    run_algorithm_mode()\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/training.py\", line 68, in run_algorithm_mode\n    checkpoint_config=checkpoint_config\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 127, in sagemaker_train\n    train_dmatrix, val_dmatrix = get_validated_dmatrices(train_path, val_path, file_type, csv_weights, is_pipe)\n  File \"/miniconda3/lib/python3.6/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 78, in get_validated_dmatrices\n    validate_data_f"
     ]
    }
   ],
   "source": [
    "# Execute the XGBoost training job\n",
    "estimator.fit({'train': train_input, 'validation': validation_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
