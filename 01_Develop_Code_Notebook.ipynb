{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning a BERT Model and Create a Text Classifier\n",
    "\n",
    "We have already performed the Feature Engineering to create BERT embeddings from the `reviews_body` text using the pre-trained BERT model, and split the dataset into train, validation and test files. To optimize for Tensorflow training, we saved the files in TFRecord format. \n",
    "\n",
    "Now, let’s fine-tune the BERT model to our Customer Reviews Dataset and add a new classification layer to predict the `star_rating` for a given `review_body`.\n",
    "\n",
    "![BERT Training](img/bert_training.png)\n",
    "\n",
    "As mentioned earlier, BERT’s attention mechanism is called a Transformer. This is, not coincidentally, the name of the popular BERT Python library, “Transformers,” maintained by a company called [HuggingFace](https://github.com/huggingface/transformers). We will use a variant of BERT called [DistilBert](https://arxiv.org/pdf/1910.01108.pdf) which requires less memory and compute, but maintains very good accuracy on our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO 1: \n",
    "# Develop Model Training Code In Noteboook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q scikit-learn==0.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data='./input/data/train'\n",
    "validation_data='./input/data/validation'\n",
    "test_data='./input/data/test'\n",
    "local_model_dir='./model/'\n",
    "num_gpus=0\n",
    "input_data_config='File'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "learning_rate=0.00001\n",
    "epsilon=0.00000001\n",
    "train_batch_size=8\n",
    "validation_batch_size=8\n",
    "test_batch_size=8\n",
    "train_steps_per_epoch=1\n",
    "validation_steps=1\n",
    "test_steps=1\n",
    "use_xla=True\n",
    "use_amp=False\n",
    "max_seq_length=64\n",
    "freeze_bert_layer=True\n",
    "run_validation=True\n",
    "run_test=True\n",
    "run_sample_predictions=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Variables:\n",
      "{'AWS_AUTO_SCALING_HOME': '/opt/aws/apitools/as',\n",
      " 'AWS_CLOUDWATCH_HOME': '/opt/aws/apitools/mon',\n",
      " 'AWS_ELB_HOME': '/opt/aws/apitools/elb',\n",
      " 'AWS_PATH': '/opt/aws',\n",
      " 'BASH_FUNC_module()': '() '\n",
      "                       '{  '\n",
      "                       'eval '\n",
      "                       '`/usr/bin/modulecmd '\n",
      "                       'bash '\n",
      "                       '$*`\\n'\n",
      "                       '}',\n",
      " 'CLICOLOR': '1',\n",
      " 'CONDA_DEFAULT_ENV': 'python3',\n",
      " 'CONDA_EXE': '/home/ec2-user/anaconda3/bin/conda',\n",
      " 'CONDA_PREFIX': '/home/ec2-user/anaconda3/envs/python3',\n",
      " 'CONDA_PREFIX_1': '/home/ec2-user/anaconda3/envs/JupyterSystemEnv',\n",
      " 'CONDA_PREFIX_2': '/home/ec2-user/anaconda3',\n",
      " 'CONDA_PROMPT_MODIFIER': '(python3) ',\n",
      " 'CONDA_PYTHON_EXE': '/home/ec2-user/anaconda3/bin/python',\n",
      " 'CONDA_SHLVL': '3',\n",
      " 'CUDA_PATH': '/usr/local/cuda-10.0',\n",
      " 'CVS_RSH': 'ssh',\n",
      " 'EC2_AMITOOL_HOME': '/opt/aws/amitools/ec2',\n",
      " 'EC2_HOME': '/opt/aws/apitools/ec2',\n",
      " 'ENV_NAME': 'python3',\n",
      " 'GIT_PAGER': 'cat',\n",
      " 'GIT_PYTHON_REFRESH': 'quiet',\n",
      " 'GSETTINGS_SCHEMA_DIR': '/home/ec2-user/anaconda3/envs/JupyterSystemEnv/share/glib-2.0/schemas',\n",
      " 'GSETTINGS_SCHEMA_DIR_CONDA_BACKUP': '',\n",
      " 'HISTCONTROL': 'ignoredups',\n",
      " 'HISTSIZE': '1000',\n",
      " 'HOME': '/home/ec2-user',\n",
      " 'HOSTNAME': 'ip-172-16-71-223',\n",
      " 'JAVA_HOME': '/usr/lib/jvm/java',\n",
      " 'JAVA_HOME_CONDA_BACKUP': '/usr/lib/jvm/java',\n",
      " 'JAVA_LD_LIBRARY_PATH': '/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/server',\n",
      " 'JAVA_LD_LIBRARY_PATH_BACKUP': '',\n",
      " 'JPY_PARENT_PID': '4401',\n",
      " 'KMP_DUPLICATE_LIB_OK': 'True',\n",
      " 'KMP_INIT_AT_FORK': 'FALSE',\n",
      " 'LANG': 'en_US.UTF-8',\n",
      " 'LD_LIBRARY_PATH': '/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/extras/CUPTI/lib64:/usr/local/cuda-10.0/lib:/usr/local/cuda-10.0/efa/lib:/opt/amazon/efa/lib:/opt/amazon/efa/lib64:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:',\n",
      " 'LD_LIBRARY_PATH_WITHOUT_CUDA': '/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:',\n",
      " 'LD_LIBRARY_PATH_WITH_DEFAULT_CUDA': '/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/usr/local/cuda-10.0/lib/:/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/usr/local/cuda-10.0/lib/:/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/usr/local/cuda-10.0/lib/:',\n",
      " 'LESSOPEN': '||/usr/bin/lesspipe.sh '\n",
      "             '%s',\n",
      " 'LESS_TERMCAP_mb': '\\x1b[01;31m',\n",
      " 'LESS_TERMCAP_md': '\\x1b[01;38;5;208m',\n",
      " 'LESS_TERMCAP_me': '\\x1b[0m',\n",
      " 'LESS_TERMCAP_se': '\\x1b[0m',\n",
      " 'LESS_TERMCAP_ue': '\\x1b[0m',\n",
      " 'LESS_TERMCAP_us': '\\x1b[04;38;5;111m',\n",
      " 'LOADEDMODULES': '',\n",
      " 'LOGNAME': 'ec2-user',\n",
      " 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:',\n",
      " 'MAIL': '/var/spool/mail/ec2-user',\n",
      " 'MANPATH': ':',\n",
      " 'MODULEPATH': '/usr/share/Modules/modulefiles:/etc/modulefiles',\n",
      " 'MODULESHOME': '/usr/share/Modules',\n",
      " 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',\n",
      " 'PAGER': 'cat',\n",
      " 'PATH': '/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/usr/local/mpi/bin:/usr/libexec/gcc/x86_64-amazon-linux/4.8.5:/opt/amazon/openmpi/bin:/opt/amazon/efa/bin:/home/ec2-user/anaconda3/envs/python3/bin:/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/usr/local/mpi/bin:/usr/libexec/gcc/x86_64-amazon-linux/4.8.5:/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/home/ec2-user/.dl_binaries/bin:/usr/local/mpi/bin:/home/ec2-user/anaconda3/bin:/home/ec2-user/anaconda3/condabin:/home/ec2-user/anaconda3/bin:/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/usr/local/mpi/bin:/usr/libexec/gcc/x86_64-amazon-linux/4.8.5:/opt/amazon/openmpi/bin:/opt/amazon/efa/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/aws/bin:/opt/aws/bin',\n",
      " 'PKG_CONFIG_PATH': '/usr/local/lib/pkgconfig:/usr/local/lib/pkgconfig:/usr/local/lib/pkgconfig:/usr/local/lib/pkgconfig:',\n",
      " 'PWD': '/home/ec2-user',\n",
      " 'PYTHON_INSTALL_LAYOUT': 'amzn',\n",
      " 'PYTHON_VERSION': '3.6',\n",
      " 'SHELL': '/bin/sh',\n",
      " 'SHLVL': '1',\n",
      " 'TERM': 'xterm-color',\n",
      " 'USER': 'ec2-user',\n",
      " '_': '/bin/env\\n',\n",
      " '_CE_CONDA': '',\n",
      " '_CE_M': ''}\n",
      "train_data ./input/data/train\n",
      "validation_data ./input/data/validation\n",
      "test_data ./input/data/test\n",
      "local_model_dir ./model/\n",
      "num_gpus 0\n",
      "use_xla True\n",
      "use_amp False\n",
      "max_seq_length 64\n",
      "train_batch_size 8\n",
      "validation_batch_size 8\n",
      "test_batch_size 8\n",
      "epochs 1\n",
      "learning_rate 1e-05\n",
      "epsilon 1e-08\n",
      "train_steps_per_epoch 1\n",
      "validation_steps 1\n",
      "test_steps 1\n",
      "freeze_bert_layer True\n",
      "run_validation True\n",
      "run_test True\n",
      "run_sample_predictions True\n",
      "input_data_config File\n",
      "Using pipe_mode: False\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "train_data_filenames ['./input/data/train/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord', './input/data/train/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord']\n",
      "***** Using input_filenames ['./input/data/train/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord', './input/data/train/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord']\n",
      "WARNING:tensorflow:From <ipython-input-6-f872b7238625>:76: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "**************** train *****************\n",
      "{'input_ids': array([[  101, 12202,  2444,  5779,  2003,  6429,   999,  2017,  2064,\n",
      "         2707,  2011,  2652,  2007,  2115,  2814,  1998,  3331,  2000,\n",
      "         2068,  1999,  1037,  2283,  2000,  2652,  2007,  6721,  2111,\n",
      "         1998,  2635,  2000,  2068,  1999,  2208,  2377,  1012, 12202,\n",
      "         2444,  2038, 10106,  2008,  2017,  2064,  7796,  1998,  5566,\n",
      "         2114,  2814,  1999,  2399,  1012,  1996,  2069,  2919,  2518,\n",
      "         2055, 12202,  2444,  2003,  2008,  2009,  5366,  2769,  1012,\n",
      "          102],\n",
      "       [  101,  2307,  2399,  2005,  1019, 14189,  1012,  2089,  2022,\n",
      "         2214,  2021,  2027,  1005,  2128,  2751,  1012, 12476,  2399,\n",
      "         1010,  3976,  2481,  1005,  1056,  2131,  2151,  2488,  1012,\n",
      "         2052, 16755,  1012,   102,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2026,  1023,  2095,  2214,  2365,  7459,  2009,   999,\n",
      "         2009,  2003,  1996,  2034,  2051,  1045,  3641,  1037,  2208,\n",
      "         2008,  2017,  8816,  2013,  1996,  4274,  2007,  2053,  5860,\n",
      "         2061,  1045,  2001,  6091,  1010,  2021,  2009,  2003,  2307,\n",
      "         1010,  2053,  3471,   999,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  1045,  4149,  2023,  1998,  2224,  2009,  2021,  2036,\n",
      "         2031,  3935,  2291,  2729,  4013,  7209,  2029,  2038,  2328,\n",
      "         1999,  3424, 23350,  1998,  2978, 12625,  1012,  2172,  2488,\n",
      "         4031,  1998,  2009,  3475,  2102,  6450,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2204,  4031,  1010,  3435,  7829,  1010,  2157,  3976,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2057,  4033,  1005,  1056,  2018,  2151,  3471,  2006,\n",
      "         2256,  3274,  2144,  2057,  1005,  2310,  2042,  2478,  2023,\n",
      "         4031,  1010,  1998,  2057,  1005,  2310,  2018,  2009,  2005,\n",
      "         1037,  3232,  1997,  2086,  2085,  1012,  2009, 14409,  2004,\n",
      "         2734,  1998,  4107, 18739,  1010,  2021,  2061,  2521,  2057,\n",
      "         4033,  1005,  1056,  2359,  2000,  5247,  1996,  4469,  2769,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2074,  2066,  2000,  5247,  2009,  1010,  2049,  1037,\n",
      "         2204,  4031,  2000,  2224,  1010,  3733,  1012,  1045,  4299,\n",
      "         1045,  8725,  2062,  2055,  2769,  1998,  9651,  2009,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101, 22817,  2023,  2000,  2224,  2004,  1037, 25416, 21898,\n",
      "         2121,  1012,  2044, 23658,  1998,  2128,  1011, 23658,  2195,\n",
      "         2335,  1010,  2009,  2145,  2515,  2025,  2147,  1012,  2123,\n",
      "         1005,  1056,  5949,  2115,  2051,  1012,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0]]), 'input_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'label_ids': array([3, 4, 4, 2, 4, 3, 2, 0]), 'segment_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Sucessfully downloaded after 0 retries.\n",
      "** use_amp False\n",
      "*** OPTIMIZER <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f906c5480f0> ***\n",
      "Compiled model <transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification object at 0x7f906c548320>\n",
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "distilbert (TFDistilBertMain multiple                  66362880  \n",
      "_________________________________________________________________\n",
      "pre_classifier (Dense)       multiple                  590592    \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  3845      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 66,957,317\n",
      "Trainable params: 594,437\n",
      "Non-trainable params: 66,362,880\n",
      "_________________________________________________________________\n",
      "None\n",
      "validation_data_filenames ['./input/data/validation/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord', './input/data/validation/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord']\n",
      "***** Using input_filenames ['./input/data/validation/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord', './input/data/validation/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord']\n",
      "**************** validation *****************\n",
      "{'input_ids': array([[  101,  9733,  2001,  2383,  1037,  5096,  2006,  2023,  4031,\n",
      "         2055,  1037,  2733,  2077,  2258,  6286,  1012,  1045,  1005,\n",
      "         1049,  2667,  2000,  3828,  2070,  5356,  2157,  2085,  1998,\n",
      "         2245,  1045,  1005,  1040,  2202,  1996,  3891,  1012,  9826,\n",
      "         1010,  2130,  2295, 15386,  4171,  2003,  2025,  1996,  2087,\n",
      "         6429,  4031,  2412,  1010,  1045,  5791,  2066,  2009,  1037,\n",
      "         2843,  2488,  1012,  1045,  2471,  2435,  2039,  1998,  4149,\n",
      "          102],\n",
      "       [  101,  2042,  2478,  2005,  2055,  1018,  2086,  1012,  2053,\n",
      "        15245,  1012,  5432,  3769, 11139,  2055,  2184,  1011,  2260,\n",
      "         2335,  1012,  1045,  1005,  1049,  1037,  3492,  6176,  5310,\n",
      "         4953,  2054,  1045, 11562,  2006,  1012,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2017,  2031,  2000,  2191,  2039,  2780,  2000,  2377,\n",
      "         2023,  2085,  2065,  2017,  2123,  2102,  2031,  2814,  2000,\n",
      "         3477,  2007,  2059,  2017,  2064,  2102,  2224,  1012,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  1045,  2572,  2025,  3407,  2007,  1996,  7968, 15288,\n",
      "         2013,  1996,  7116,  2043,  1045,  1005,  1049,  2667,  2000,\n",
      "         4553,  2129,  2000,  2377,  7433,  1012,  1045,  2031,  2025,\n",
      "         6618,  2041,  1037,  2126,  2000,  3844,  2014,  2039,   999,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  9733,  2001,  2383,  1037,  5096,  2006,  2023,  4031,\n",
      "         2055,  1037,  2733,  2077,  2258,  6286,  1012,  1045,  1005,\n",
      "         1049,  2667,  2000,  3828,  2070,  5356,  2157,  2085,  1998,\n",
      "         2245,  1045,  1005,  1040,  2202,  1996,  3891,  1012,  9826,\n",
      "         1010,  2130,  2295, 15386,  4171,  2003,  2025,  1996,  2087,\n",
      "         6429,  4031,  2412,  1010,  1045,  5791,  2066,  2009,  1037,\n",
      "         2843,  2488,  1012,  1045,  2471,  2435,  2039,  1998,  4149,\n",
      "          102],\n",
      "       [  101,  2042,  2478,  2005,  2055,  1018,  2086,  1012,  2053,\n",
      "        15245,  1012,  5432,  3769, 11139,  2055,  2184,  1011,  2260,\n",
      "         2335,  1012,  1045,  1005,  1049,  1037,  3492,  6176,  5310,\n",
      "         4953,  2054,  1045, 11562,  2006,  1012,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2017,  2031,  2000,  2191,  2039,  2780,  2000,  2377,\n",
      "         2023,  2085,  2065,  2017,  2123,  2102,  2031,  2814,  2000,\n",
      "         3477,  2007,  2059,  2017,  2064,  2102,  2224,  1012,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  1045,  2572,  2025,  3407,  2007,  1996,  7968, 15288,\n",
      "         2013,  1996,  7116,  2043,  1045,  1005,  1049,  2667,  2000,\n",
      "         4553,  2129,  2000,  2377,  7433,  1012,  1045,  2031,  2025,\n",
      "         6618,  2041,  1037,  2126,  2000,  3844,  2014,  2039,   999,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0]]), 'input_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'label_ids': array([2, 3, 1, 2, 2, 3, 1, 2]), 'segment_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Starting Training and Validation...\n",
      "Train for 1 steps, validate for 1 steps\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.6254 - accuracy: 0.1250 - val_loss: 1.6209 - val_accuracy: 0.0000e+00\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7f9028797d30>\n",
      "test_data_filenames ['./input/data/test/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord', './input/data/test/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord']\n",
      "***** Using input_filenames ['./input/data/test/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord', './input/data/test/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord']\n",
      "**************** test *****************\n",
      "{'input_ids': array([[  101,  6581,  4031,  2008, 14409,  4703,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2069,  2138,  1045,  2342,  2009,  1012,  2174,  1010,\n",
      "        15386,  4171,  2003,  2092,  4114,  1998,  7126,  1996,  2852,\n",
      "        15979,  2854,  1997,  4171,  5651,  1012,  3733,  2000,  2224,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2023, 11989, 11721,  2213,  2860,  2003,  2062,  1037,\n",
      "        12204,  1010,  2025,  1037,  2208,  1012,  1045,  2699,  2195,\n",
      "         2335,  1998,  2169,  2051,  2071,  2025,  5047,  4531,  1998,\n",
      "         4109,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  1996,  8816,  1045,  4156,  3478,  1012,  1045,  2628,\n",
      "         2035,  1997,  1996,  4084,  1010,  2021,  2071,  2025,  2131,\n",
      "         1996,  8816,  2000,  2736, 11178,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  6581,  4031,  2008, 14409,  4703,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2069,  2138,  1045,  2342,  2009,  1012,  2174,  1010,\n",
      "        15386,  4171,  2003,  2092,  4114,  1998,  7126,  1996,  2852,\n",
      "        15979,  2854,  1997,  4171,  5651,  1012,  3733,  2000,  2224,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2023, 11989, 11721,  2213,  2860,  2003,  2062,  1037,\n",
      "        12204,  1010,  2025,  1037,  2208,  1012,  1045,  2699,  2195,\n",
      "         2335,  1998,  2169,  2051,  2071,  2025,  5047,  4531,  1998,\n",
      "         4109,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  1996,  8816,  1045,  4156,  3478,  1012,  1045,  2628,\n",
      "         2035,  1997,  1996,  4084,  1010,  2021,  2071,  2025,  2131,\n",
      "         1996,  8816,  2000,  2736, 11178,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0]]), 'input_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'label_ids': array([4, 3, 0, 0, 4, 3, 0, 0]), 'segment_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Starting test...\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6081 - accuracy: 0.2500\n",
      "Test history [1.6081469058990479, 0.25]\n",
      "transformer_fine_tuned_model_path ./model/transformers/fine-tuned/\n",
      "tensorflow_saved_model_path ./model/tensorflow/saved_model/0\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f906c52fef0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f906c5a2da0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f906db340f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f906c509828>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f90642bd240>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f90641efda0>, because it is not built.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./model/tensorflow/saved_model/0/assets\n",
      "inference_device -1\n",
      "I loved it!  I will recommend this to everyone. [{'label': 5, 'score': 0.21773398}]\n",
      "It's OK. [{'label': 5, 'score': 0.22062178}]\n",
      "Really bad.  I hope they don't make this anymore. [{'label': 5, 'score': 0.21828969}]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import easydict\n",
    "from glob import glob\n",
    "import pprint\n",
    "import argparse\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers.configuration_distilbert import DistilBertConfig\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "CLASSES = [1, 2, 3, 4, 5]\n",
    "\n",
    "def select_data_and_label_from_record(record):\n",
    "    x = {\n",
    "        'input_ids': record['input_ids'],\n",
    "        'input_mask': record['input_mask'],\n",
    "        'segment_ids': record['segment_ids']\n",
    "    }\n",
    "\n",
    "    y = record['label_ids']\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "def file_based_input_dataset_builder(channel,\n",
    "                                     input_filenames,\n",
    "                                     pipe_mode,\n",
    "                                     is_training,\n",
    "                                     drop_remainder,\n",
    "                                     batch_size,\n",
    "                                     epochs,\n",
    "                                     steps_per_epoch,\n",
    "                                     max_seq_length):\n",
    "\n",
    "    # For training, we want a lot of parallel reading and shuffling.\n",
    "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
    "\n",
    "    if pipe_mode:\n",
    "            print('***** Using pipe_mode with channel {}'.format(channel))\n",
    "            from sagemaker_tensorflow import PipeModeDataset\n",
    "            dataset = PipeModeDataset(channel=channel,\n",
    "                                      record_format='TFRecord')\n",
    "    else:\n",
    "        print('***** Using input_filenames {}'.format(input_filenames))\n",
    "        dataset = tf.data.TFRecordDataset(input_filenames)\n",
    "    \n",
    "    dataset = dataset.repeat(epochs * steps_per_epoch * 100)\n",
    "\n",
    "    name_to_features = {\n",
    "      \"input_ids\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"input_mask\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"segment_ids\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"label_ids\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    def _decode_record(record, name_to_features):\n",
    "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "        record = tf.io.parse_single_example(record, name_to_features)\n",
    "        return record\n",
    "    \n",
    "    dataset = dataset.apply(\n",
    "        tf.data.experimental.map_and_batch(\n",
    "          lambda record: _decode_record(record, name_to_features),\n",
    "          batch_size=batch_size,\n",
    "          drop_remainder=drop_remainder,\n",
    "          num_parallel_calls=tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size=1000,\n",
    "                              reshuffle_each_iteration=True)\n",
    "    \n",
    "    row_count = 0\n",
    "    print('**************** {} *****************'.format(channel))\n",
    "    for row in dataset.as_numpy_iterator():\n",
    "        if row_count == 1:\n",
    "            break\n",
    "        print(row)\n",
    "        row_count = row_count + 1\n",
    "    return dataset\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    args=easydict.EasyDict({\n",
    "        'train_data': train_data,\n",
    "        'validation_data': validation_data,\n",
    "        'test_data': test_data,\n",
    "        'local_model_dir': local_model_dir,\n",
    "        'num_gpus': num_gpus,\n",
    "        'use_xla': use_xla,\n",
    "        'use_amp': use_amp,\n",
    "        'max_seq_length': max_seq_length,\n",
    "        'train_batch_size': train_batch_size,\n",
    "        'validation_batch_size': validation_batch_size,\n",
    "        'test_batch_size': test_batch_size,\n",
    "        'epochs': epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'epsilon': epsilon,\n",
    "        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "        'validation_steps': validation_steps,\n",
    "        'test_steps': test_steps,\n",
    "        'freeze_bert_layer': freeze_bert_layer,\n",
    "        'run_validation': run_validation,\n",
    "        'run_test': run_test,\n",
    "        'run_sample_predictions': run_sample_predictions,\n",
    "        'input_data_config': input_data_config\n",
    "    })\n",
    "    \n",
    "    \n",
    "    env_var = os.environ \n",
    "    print(\"Environment Variables:\") \n",
    "    pprint.pprint(dict(env_var), width = 1) \n",
    "    \n",
    "    train_data = args.train_data\n",
    "    print('train_data {}'.format(train_data))\n",
    "    validation_data = args.validation_data\n",
    "    print('validation_data {}'.format(validation_data))\n",
    "    test_data = args.test_data\n",
    "    print('test_data {}'.format(test_data))    \n",
    "    local_model_dir = args.local_model_dir\n",
    "    print('local_model_dir {}'.format(local_model_dir))         \n",
    "    num_gpus = args.num_gpus\n",
    "    print('num_gpus {}'.format(num_gpus))   \n",
    "    use_xla = args.use_xla\n",
    "    print('use_xla {}'.format(use_xla))    \n",
    "    use_amp = args.use_amp\n",
    "    print('use_amp {}'.format(use_amp))    \n",
    "    max_seq_length = args.max_seq_length\n",
    "    print('max_seq_length {}'.format(max_seq_length))    \n",
    "    train_batch_size = args.train_batch_size\n",
    "    print('train_batch_size {}'.format(train_batch_size))    \n",
    "    validation_batch_size = args.validation_batch_size\n",
    "    print('validation_batch_size {}'.format(validation_batch_size))    \n",
    "    test_batch_size = args.test_batch_size\n",
    "    print('test_batch_size {}'.format(test_batch_size))    \n",
    "    epochs = args.epochs\n",
    "    print('epochs {}'.format(epochs))    \n",
    "    learning_rate = args.learning_rate\n",
    "    print('learning_rate {}'.format(learning_rate))    \n",
    "    epsilon = args.epsilon\n",
    "    print('epsilon {}'.format(epsilon))    \n",
    "    train_steps_per_epoch = args.train_steps_per_epoch\n",
    "    print('train_steps_per_epoch {}'.format(train_steps_per_epoch))    \n",
    "    validation_steps = args.validation_steps\n",
    "    print('validation_steps {}'.format(validation_steps))    \n",
    "    test_steps = args.test_steps\n",
    "    print('test_steps {}'.format(test_steps))    \n",
    "    freeze_bert_layer = args.freeze_bert_layer\n",
    "    print('freeze_bert_layer {}'.format(freeze_bert_layer))    \n",
    "    run_validation = args.run_validation\n",
    "    print('run_validation {}'.format(run_validation))    \n",
    "    run_test = args.run_test\n",
    "    print('run_test {}'.format(run_test))    \n",
    "    run_sample_predictions = args.run_sample_predictions\n",
    "    print('run_sample_predictions {}'.format(run_sample_predictions))\n",
    "    input_data_config = args.input_data_config\n",
    "    print('input_data_config {}'.format(input_data_config))\n",
    "    \n",
    "    # Determine if PipeMode is enabled \n",
    "    pipe_mode = (input_data_config.find('Pipe') >= 0)\n",
    "    print('Using pipe_mode: {}'.format(pipe_mode))\n",
    " \n",
    "    # Model Output \n",
    "    transformer_fine_tuned_model_path = os.path.join(local_model_dir, 'transformers/fine-tuned/')\n",
    "    os.makedirs(transformer_fine_tuned_model_path, exist_ok=True)\n",
    "\n",
    "    # SavedModel Output\n",
    "    tensorflow_saved_model_path = os.path.join(local_model_dir, 'tensorflow/saved_model/0')\n",
    "    os.makedirs(tensorflow_saved_model_path, exist_ok=True) \n",
    "    \n",
    "    distributed_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "    with distributed_strategy.scope():\n",
    "        tf.config.optimizer.set_jit(use_xla)\n",
    "        tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": use_amp})\n",
    "\n",
    "        train_data_filenames = glob(os.path.join(train_data, '*.tfrecord'))\n",
    "        print('train_data_filenames {}'.format(train_data_filenames))\n",
    "        train_dataset = file_based_input_dataset_builder(\n",
    "            channel='train',\n",
    "            input_filenames=train_data_filenames,\n",
    "            pipe_mode=pipe_mode,\n",
    "            is_training=True,\n",
    "            drop_remainder=False,\n",
    "            batch_size=train_batch_size,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=train_steps_per_epoch,\n",
    "            max_seq_length=max_seq_length).map(select_data_and_label_from_record)\n",
    "\n",
    "        tokenizer = None\n",
    "        config = None\n",
    "        model = None\n",
    "\n",
    "        successful_download = False\n",
    "        retries = 0\n",
    "        while (retries < 5 and not successful_download):\n",
    "            try:\n",
    "                tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "                config = DistilBertConfig.from_pretrained('distilbert-base-uncased',\n",
    "                                                          num_labels=len(CLASSES))\n",
    "                model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',\n",
    "                                                                              config=config)\n",
    "                successful_download = True\n",
    "                print('Sucessfully downloaded after {} retries.'.format(retries))\n",
    "            except:\n",
    "                retries = retries + 1\n",
    "                random_sleep = random.randint(1, 30)\n",
    "                print('Retry #{}.  Sleeping for {} seconds'.format(retries, random_sleep))\n",
    "                time.sleep(random_sleep)\n",
    "\n",
    "        callbacks = []       \n",
    "        initial_epoch_number = 0 \n",
    "\n",
    "        if not tokenizer or not model or not config:\n",
    "            print('Not properly initialized...')\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
    "        print('** use_amp {}'.format(use_amp))        \n",
    "        if use_amp:\n",
    "            # loss scaling is currently required when using mixed precision\n",
    "            optimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(optimizer, 'dynamic')\n",
    "  \n",
    "        print('*** OPTIMIZER {} ***'.format(optimizer))\n",
    "        \n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "        print('Compiled model {}'.format(model))          \n",
    "        model.layers[0].trainable = not freeze_bert_layer\n",
    "        print(model.summary())\n",
    "\n",
    "        if run_validation:\n",
    "            validation_data_filenames = glob(os.path.join(validation_data, '*.tfrecord'))\n",
    "            print('validation_data_filenames {}'.format(validation_data_filenames))\n",
    "            validation_dataset = file_based_input_dataset_builder(\n",
    "                channel='validation',\n",
    "                input_filenames=validation_data_filenames,\n",
    "                pipe_mode=pipe_mode,\n",
    "                is_training=False,\n",
    "                drop_remainder=False,\n",
    "                batch_size=validation_batch_size,\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=validation_steps,\n",
    "                max_seq_length=max_seq_length).map(select_data_and_label_from_record)\n",
    "            \n",
    "            print('Starting Training and Validation...')\n",
    "            validation_dataset = validation_dataset.take(validation_steps)\n",
    "            train_and_validation_history = model.fit(train_dataset,\n",
    "                                                     shuffle=True,\n",
    "                                                     epochs=epochs,\n",
    "                                                     initial_epoch=initial_epoch_number,\n",
    "                                                     steps_per_epoch=train_steps_per_epoch,\n",
    "                                                     validation_data=validation_dataset,\n",
    "                                                     validation_steps=validation_steps,\n",
    "                                                     callbacks=callbacks)                                \n",
    "            print(train_and_validation_history)\n",
    "        else: # Not running validation\n",
    "            print('Starting Training (Without Validation)...')\n",
    "            train_history = model.fit(train_dataset,\n",
    "                                      shuffle=True,\n",
    "                                      epochs=epochs,\n",
    "                                      initial_epoch=initial_epoch_number,\n",
    "                                      steps_per_epoch=train_steps_per_epoch,\n",
    "                                      callbacks=callbacks)                \n",
    "            print(train_history)\n",
    "\n",
    "        if run_test:\n",
    "            test_data_filenames = glob(os.path.join(test_data, '*.tfrecord'))\n",
    "            print('test_data_filenames {}'.format(test_data_filenames))\n",
    "            test_dataset = file_based_input_dataset_builder(\n",
    "                channel='test',\n",
    "                input_filenames=test_data_filenames,\n",
    "                pipe_mode=pipe_mode,\n",
    "                is_training=False,\n",
    "                drop_remainder=False,\n",
    "                batch_size=test_batch_size,\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=test_steps,\n",
    "                max_seq_length=max_seq_length).map(select_data_and_label_from_record)\n",
    "\n",
    "            print('Starting test...')\n",
    "            test_history = model.evaluate(test_dataset,\n",
    "                                          steps=test_steps,\n",
    "                                          callbacks=callbacks)\n",
    "                                 \n",
    "            print('Test history {}'.format(test_history))\n",
    "            \n",
    "        # Save the Fine-Tuned Transformers Model as a New \"Pre-Trained\" Model\n",
    "        print('transformer_fine_tuned_model_path {}'.format(transformer_fine_tuned_model_path))   \n",
    "        model.save_pretrained(transformer_fine_tuned_model_path)\n",
    "\n",
    "        # Save the TensorFlow SavedModel for Serving Predictions\n",
    "        print('tensorflow_saved_model_path {}'.format(tensorflow_saved_model_path))   \n",
    "        model.save(tensorflow_saved_model_path, save_format='tf')\n",
    "                \n",
    "    if run_sample_predictions:\n",
    "        loaded_model = TFDistilBertForSequenceClassification.from_pretrained(transformer_fine_tuned_model_path,\n",
    "                                                                       id2label={\n",
    "                                                                        0: 1,\n",
    "                                                                        1: 2,\n",
    "                                                                        2: 3,\n",
    "                                                                        3: 4,\n",
    "                                                                        4: 5\n",
    "                                                                       },\n",
    "                                                                       label2id={\n",
    "                                                                        1: 0,\n",
    "                                                                        2: 1,\n",
    "                                                                        3: 2,\n",
    "                                                                        4: 3,\n",
    "                                                                        5: 4\n",
    "                                                                       })\n",
    "\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "        if num_gpus >= 1:\n",
    "            inference_device = 0 # GPU 0\n",
    "        else:\n",
    "            inference_device = -1 # CPU\n",
    "        print('inference_device {}'.format(inference_device))\n",
    "\n",
    "        inference_pipeline = TextClassificationPipeline(model=loaded_model, \n",
    "                                                        tokenizer=tokenizer,\n",
    "                                                        framework='tf',\n",
    "                                                        device=inference_device)  \n",
    "\n",
    "        print(\"\"\"I loved it!  I will recommend this to everyone.\"\"\", inference_pipeline(\"\"\"I loved it!  I will recommend this to everyone.\"\"\"))\n",
    "        print(\"\"\"It's OK.\"\"\", inference_pipeline(\"\"\"It's OK.\"\"\"))\n",
    "        print(\"\"\"Really bad.  I hope they don't make this anymore.\"\"\", inference_pipeline(\"\"\"Really bad.  I hope they don't make this anymore.\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
